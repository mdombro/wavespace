# wavespace
Wide-area Acoustic Vector-field Estimation for Spatial Probing & Array Calibration Environment

... measuring waves, in 3D


# Developer Environment Setup

## Python workspace
1. Install Python 3.10+ plus `pip`.
2. Create a virtual environment:
   ```bash
   python -m venv .venv
   source .venv/bin/activate
   pip install -U pip
   ```
3. Install dependencies shared across the visualization and tooling scripts:
   ```bash
   pip install -r requirements.txt
   ```
   (Add any project-specific extras as needed.)

## Pico C/C++ toolchain (Raspberry Pi Pico / Pico 2 W)
1. Install VS Code and add the official **Raspberry Pi Pico** extension.
2. Click on the extension on the side bar and then select `Import Project`
3. Under Location, select the `discrete-pdm-capture` folder and then select import. 
4. Make sure the `pico2_w` board is selected in the lower right status bar
5. The pico extension should automatically download and install the SDK and setup the relevant toolchains required.


## Flashing and Running `discrete-pdm-capture`
1. Built the firmware via the extension by selecting `Compile Project` in either the extension side bar menu, or the `compile` command in the lower right bar.
2. Put the Pico 2 W into UF2 bootloader mode (hold BOOTSEL while plugging in USB).
3. Copy the generated `pico_pdm_capture.uf2` that will be generated by the compile command inside `discrete-pdm-capture/build` folder onto the mass-storage drive that appears (`RP2350`).
4. The board should reboot and begin sending out data on triggers

## Capturing Raw PDM over USB
Run the `capture-listener.py` file while the pico is plugged into the host capture device. This script will capture and save the PDM data to disk for later processing

## Parsing the Bit Stream (`post-process-pdm.py`)
1. The capture script will create a folder `pdm_captures` which contains a `.json` file and a binary capture file for each PDM microphone. The JSON file specifies how much was captured for each trigger and some other meta-data. 
2. Run the `post-process-pdm.py` script on the generated data to generate a set of filtered data that is ready for visualization
3. You will also need to have an `events.csv` file that specifies for each trigger index the corresponding XYZ location in the gantry space. This is a work in progress from the `gantry_scripting` set of scripts.
### Example
```bash
python post-process-pdm.py --captures pdm_captures --xyz events.csv --out filtered-captures --decimation 1 
```

## Generating Visualization Sample Data (`pyvista-viz.py`)
1. Finally run the visualization script to generate the interactive GUI to watch the captured and synchornized audio data. 

### Example
```bash
python visualization/pyvista-viz.py --path filtered-captures/ --mode point
```

## Running the Zig-Zag Toolpath Visualizer
`zigzag3d.py` produces strict XY-then-Z paths and optional plots/G-code.
Examples:
```bash
python zigzag3d.py --W 120 --H 80 --Z_top 40 --stepover 5 --layer_h 2 --plot
python zigzag3d.py --W 100 --H 100 --Z_top 50 --stepover 4 --layer_h 1.5 --export fill.nc
```
Flags:
- `--plot`: shows a 3D matplotlib preview.
- `--export`: writes a G-code file with the strict path.
- `--start-left`, `--start-bottom`: control raster direction.

Refer to `zigzag3d.py --help` for all options.
